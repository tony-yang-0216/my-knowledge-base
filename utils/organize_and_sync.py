import os
import re
import sys
import time
import json
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv
from google import genai
from notion_client import Client
from md2notionpage.core import parse_markdown_to_notion_blocks
from categories import get_categories_prompt
from prompts import build_organize_prompt

# ç’°å¢ƒè®Šæ•¸è¨­å®šï¼ˆæœ¬åœ°å¾ .env è¼‰å…¥ï¼ŒCI å¾ GitHub Secrets è®€å–ï¼‰
load_dotenv()

NOTION_TOKEN = os.environ.get("NOTION_TOKEN")
DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

# åˆå§‹åŒ–
gemini_client = genai.Client(api_key=GEMINI_API_KEY)
notion = Client(auth=NOTION_TOKEN, notion_version="2022-06-28")

NOTES_DIR = "notes"

def get_draft_pages():
    # temp_meta = notion.databases.retrieve(database_id=DATABASE_ID)
    # print(f"ç‰©ä»¶é¡å‹: {temp_meta.get('object')}")
    results = []
    start_cursor = None
    while True:
        response = notion.databases.query(
            database_id=DATABASE_ID,
            # åŠ ä¸Š page_size=100 æ¸›å°‘ HTTP è«‹æ±‚æ¬¡æ•¸
            page_size=100, 
            filter={"property": "Status", "status": {"equals": "Draft"}},
            start_cursor=start_cursor
        )
        batch = response.get("results", [])
        results.extend(batch)

        # å¦‚æœæ²’æœ‰ä¸‹ä¸€é ï¼Œç›´æ¥ break
        if not response.get("has_more"):
            break
            
        start_cursor = response.get("next_cursor")
    return results


def _paginate_blocks(block_id):
    """åˆ†é å–å¾—æ‰€æœ‰å­ blocks"""
    results = []
    has_more = True
    start_cursor = None
    while has_more:
        response = notion.blocks.children.list(
            block_id=block_id,
            start_cursor=start_cursor,
            page_size=100
        )
        results.extend(response.get("results", []))
        has_more = response.get("has_more", False)
        start_cursor = response.get("next_cursor")
    return results

def get_page_content(page_id):
    blocks = _paginate_blocks(page_id)
    text = ""
    for block in blocks:
        btype = block["type"]

        # æœ‰ rich_text çš„ block é¡å‹ï¼ˆparagraph, headings, lists, quotes, callout, toggleï¼‰
        if btype in ("paragraph", "heading_1", "heading_2", "heading_3",
                      "bulleted_list_item", "numbered_list_item",
                      "quote", "callout", "toggle"):
            rich_text = block[btype].get("rich_text", [])
            line = "".join([t["plain_text"] for t in rich_text])
            if btype.startswith("heading"):
                level = btype[-1]  # "1", "2", or "3"
                text += "#" * int(level) + " " + line + "\n"
            elif btype == "bulleted_list_item":
                text += "- " + line + "\n"
            elif btype == "numbered_list_item":
                text += "1. " + line + "\n"
            elif btype == "quote":
                text += "> " + line + "\n"
            else:
                text += line + "\n"

        # Code block
        elif btype == "code":
            rich_text = block["code"].get("rich_text", [])
            code = "".join([t["plain_text"] for t in rich_text])
            lang = block["code"].get("language", "")
            text += f"```{lang}\n{code}\n```\n"

        # åœ–ç‰‡
        elif btype == "image":
            image_data = block["image"]
            if image_data["type"] == "file":
                img_url = image_data["file"]["url"]
            elif image_data["type"] == "external":
                img_url = image_data["external"]["url"]
            else:
                img_url = ""
            caption = "".join([t["plain_text"] for t in image_data.get("caption", [])])
            text += f"![{caption}]({img_url})\n"

        # åˆ†éš”ç·š
        elif btype == "divider":
            text += "---\n"

        # To-do
        elif btype == "to_do":
            rich_text = block["to_do"].get("rich_text", [])
            line = "".join([t["plain_text"] for t in rich_text])
            checked = "x" if block["to_do"].get("checked") else " "
            text += f"- [{checked}] {line}\n"

    return text

def organize_with_ai(raw_text):
    categories_text = get_categories_prompt()
    prompt = build_organize_prompt(raw_text, categories_text)
    response = gemini_client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt,
        config={"response_mime_type": "application/json"}
    )

    json_str = response.text.strip()
    try:
        return json.loads(json_str)
    except json.JSONDecodeError:
        # content æ¬„ä½çš„ Markdown å¯èƒ½ç ´å£ JSONï¼Œæ‰‹å‹•æå–å„æ¬„ä½
        title = re.search(r'"title"\s*:\s*"([^"]*)"', json_str)
        category = re.search(r'"category"\s*:\s*"([^"]*)"', json_str)
        tags = re.search(r'"tags"\s*:\s*\[([^\]]*)\]', json_str)
        # content æ˜¯æœ€å¾Œä¸€å€‹æ¬„ä½ï¼Œå– "content": " ä¹‹å¾Œåˆ°æœ€å¾Œçš„ } ä¹‹å‰
        content_match = re.search(r'"content"\s*:\s*"(.*)', json_str, re.DOTALL)
        content = ""
        if content_match:
            content = content_match.group(1).rstrip().rstrip('}').rstrip().rstrip('"')
        tag_list = []
        if tags:
            tag_list = [t.strip().strip('"') for t in tags.group(1).split(',')]
        return {
            "title": title.group(1) if title else "Untitled",
            "category": category.group(1) if category else "99-Inbox",
            "tags": tag_list,
            "content": content
        }


def update_page_properties(page_id, ai_data):
    """
    æœ€å¾Œçš„çµæ¡ˆæ­¥é©Ÿï¼šä½¿ç”¨ AI æå–çš„å°ˆæ¥­æ¨™é¡Œæ›´æ–° Notion é é¢å±¬æ€§ï¼Œ
    åŒ…æ‹¬ç‹€æ…‹(Status)ã€åˆ†é¡(Category)ã€æ¨™ç±¤(Tags)èˆ‡æ›´æ–°æ™‚é–“ã€‚
    """
    try:
        # å–å¾—å°ç£æ™‚é–“ (UTC+8) çš„ ISO 8601 æ ¼å¼
        now = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%dT%H:%M:%S+08:00")
        
        # å°è£è¦æ›´æ–°çš„å±¬æ€§
        # æ³¨æ„ï¼šé€™è£¡çš„ ai_data["title"] æ˜¯ç”± AI æ ¹æ“šå…§å®¹åˆ†æå¾Œç”¢å‡ºçš„å°ˆæ¥­æ¨™é¡Œ
        props = {
            "Name": {"title": [{"text": {"content": ai_data["title"]}}]},
            "Status": {"status": {"name": "Processed"}},
            "Category": {"select": {"name": ai_data["category"]}},
            "Tags": {"multi_select": [{"name": tag} for tag in ai_data["tags"]]},
            "Updated Time": {"date": {"start": now}}
        }

        # å‘¼å« Notion API æ›´æ–°é é¢å±¬æ€§
        notion.pages.update(
            page_id=page_id,
            properties=props
        )
        print(f"âœ¨ [Notion Properties] å±¬æ€§èˆ‡æ¨™é¡Œæ›´æ–°æˆåŠŸ: {page_id}")
        
    except Exception as e:
        print(f"âŒ [Notion Properties] æ›´æ–°å¤±æ•—: {e}")
        # å‘ä¸Šæ‹‹å‡ºéŒ¯èª¤ï¼Œè®“ main() æ¨™è¨˜æ­¤é é¢è™•ç†æœªå®Œæˆï¼Œä»¥ä¾¿ä¸‹ä¸€å°æ™‚é‡æ–°å˜—è©¦
        raise


def delete_all_blocks(page_id):
    """åˆªé™¤é é¢å…§çš„æ‰€æœ‰é ‚å±¤å€å¡Š"""
    blocks = _paginate_blocks(page_id)
    for b in blocks:
        bid = b["id"]
        try:
            notion.blocks.delete(block_id=bid)
        except Exception as e:
            if "archived" in str(e).lower():
                continue
            else:
                print(f"âš ï¸ åˆªé™¤å€å¡Š {bid} æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {e}")
                raise

def _chunk_text(text, size=2000):
    """å°‡æ–‡å­—åˆ‡æˆä¸è¶…é size çš„ç‰‡æ®µï¼ˆNotion rich_text ä¸Šé™ 2000 å­—å…ƒï¼‰"""
    return [text[i:i+size] for i in range(0, len(text), size)] or [""]


def append_blocks_batched(page_id, blocks):
    for start in range(0, len(blocks), 100):
        batch = blocks[start:start + 100]
        notion.blocks.children.append(block_id=page_id, children=batch)


def _strip_invalid_links(blocks):
    """æ·±åº¦æƒææ‰€æœ‰ blocksï¼Œç§»é™¤é http/https çš„ link"""
    for block in blocks:
        btype = block.get("type", "")
        if not btype:
            continue

        block_data = block.get(btype, {})
        # 1. è™•ç†ç•¶å‰ block çš„æ–‡æœ¬
        if isinstance(block_data, dict) and "rich_text" in block_data:
            for rt in block_data.get("rich_text", []):
                text_obj = rt.get("text", {})
                link = text_obj.get("link")
                if link:
                    url = link.get("url", "")
                    if not (url.startswith("http://") or url.startswith("https://")):
                        text_obj["link"] = None
                        rt["href"] = None

        # 2. è™•ç†å­ blocks (ä¾‹å¦‚ Nested Lists, Toggle ç­‰)
        # æ³¨æ„ï¼šæœ‰äº› SDK ç‰ˆæœ¬ children æ˜¯ç›´æ¥æ›åœ¨ block ä¸‹ï¼Œæœ‰äº›æ˜¯åœ¨ block_data è£¡
        children = block_data.get("children") or block.get("children", [])
        if children:
            _strip_invalid_links(children)

    return blocks

def postprocess_blocks(blocks):
    """
    1. å¾¹åº•ç§»é™¤ AI ç”Ÿæˆçš„ Markdown æ–‡å­—ç›®éŒ„
    2. åœ¨é é¢æœ€é ‚ç«¯æ’å…¥ Notion åŸç”Ÿ TOC å€å¡Š
    """
    filtered = []
    skip_toc = False
    
    # å¸¸ç”¨æ–¼ç›®éŒ„çš„é—œéµå­—
    toc_keywords = ("ç›®éŒ„", "table of contents", "toc", "å…§å®¹å¤§ç¶±", "outline")

    for block in blocks:
        btype = block.get("type", "")
        if not btype:
            continue

        # å®‰å…¨åœ°å–å¾—è©² block çš„å…§å®¹è³‡æ–™
        block_data = block.get(btype, {})

        # A. åµæ¸¬ç›®éŒ„æ¨™é¡Œ (H1, H2, æˆ– H3)
        if btype.startswith("heading_"):
            rich_text = block_data.get("rich_text", [])
            text = "".join(t.get("plain_text", "") for t in rich_text).strip().lower()

            # å¦‚æœæ¨™é¡ŒåŒ…å«é—œéµå­—ï¼Œé–‹å•Ÿã€Œè·³éæ¨¡å¼ã€
            if any(k in text for k in toc_keywords):
                skip_toc = True
                print(f"ğŸ—‘ï¸ åµæ¸¬åˆ°å‡ç›®éŒ„æ¨™é¡Œ: '{text}'ï¼Œé–‹å§‹è·³éå¾ŒçºŒåˆ—è¡¨...")
                continue

        # B. è·³éæ¨¡å¼ï¼šé€£çºŒè·³éæ¸…å–®é …ç›® (å‡ç›®éŒ„çš„å…§å®¹)
        if skip_toc:
            if btype in ("bulleted_list_item", "numbered_list_item"):
                continue
            else:
                # é‡åˆ°éåˆ—è¡¨å€å¡Šï¼Œä»£è¡¨å‡ç›®éŒ„çµæŸï¼Œé—œé–‰è·³éæ¨¡å¼
                skip_toc = False

        filtered.append(block)

    # C. æ’å…¥ Notion åŸç”Ÿ TOC (Table of Contents)
    # æˆ‘å€‘ä¸å†æ‰¾ H1ï¼Œç›´æ¥å¼·åˆ¶æ’åœ¨ index 0 (æœ€é ‚ç«¯)ï¼Œä¿è­‰æˆåŠŸ
    notion_toc = {
        "object": "block", 
        "type": "table_of_contents",
        "table_of_contents": {"color": "default"}
    }
    
    filtered.insert(0, notion_toc)
    print("âœ… å·²åœ¨é é¢é ‚ç«¯æ’å…¥ Notion åŸç”Ÿ TOC")
    
    return filtered


def _fix_malformed_tables(md_text):
    """ä¿®å¾© md2notionpage çš„ table parser bugï¼šå–®è¡Œ pipe æ ¼å¼æœƒè§¸ç™¼ IndexErrorã€‚
    ç¢ºä¿æ‰€æœ‰ table è‡³å°‘æœ‰ header + delimiter å…©è¡Œï¼Œå¦å‰‡ escape pipesã€‚"""
    lines = md_text.split('\n')
    result = []
    table_buf = []
    table_row_re = re.compile(r'^\|.+\|$')

    def flush_table():
        if len(table_buf) < 2:
            # å–®è¡Œ pipeï¼Œescape é¿å… md2notionpage èª¤åˆ¤
            for line in table_buf:
                result.append(line.replace('|', '\\|'))
            table_buf.clear()
            return

        # æª¢æŸ¥ç¬¬äºŒè¡Œæ˜¯å¦ç‚ºåˆ†éš”ç·šï¼ˆ|---|---|ï¼‰
        delimiter_re = re.compile(r'^\|[\s:\-]+(\|[\s:\-]+)*\|$')
        if not delimiter_re.match(table_buf[1].strip()):
            # ç¼ºå°‘åˆ†éš”ç·šï¼Œæ ¹æ“šç¬¬ä¸€è¡Œæ¬„æ•¸è‡ªå‹•è£œé½Š
            col_count = table_buf[0].count('|') - 1
            delimiter = '| ' + ' | '.join(['---'] * max(col_count, 1)) + ' |'
            table_buf.insert(1, delimiter)

        result.extend(table_buf)
        table_buf.clear()

    for line in lines:
        if table_row_re.match(line.strip()):
            table_buf.append(line)
        else:
            if table_buf:
                flush_table()
            result.append(line)
    if table_buf:
        flush_table()

    return '\n'.join(result)


def _extract_and_replace_tables(md_text):
    """å¾ markdown ä¸­æå–è¡¨æ ¼ï¼Œæ›¿æ›ç‚ºä½”ä½ç¬¦ï¼Œé¿å… md2notionpage å°‡å…¶è½‰ç‚º LaTeXã€‚
    å›å‚³ (modified_md, tables_dict)ï¼Œtables_dict = {N: [table_lines]}ã€‚
    """
    lines = md_text.split('\n')
    result = []
    table_buf = []
    tables_dict = {}
    counter = 0
    table_row_re = re.compile(r'^\s*\|.+\|')

    def flush_table():
        nonlocal counter
        if not table_buf:
            return
        # è‡³å°‘éœ€è¦ header + delimiter æ‰ç®—æœ‰æ•ˆè¡¨æ ¼
        delimiter_re = re.compile(r'^\s*\|[\s:]*-+[\s:]*(\|[\s:]*-+[\s:]*)*\|')
        if len(table_buf) >= 2 and delimiter_re.match(table_buf[1]):
            tables_dict[counter] = list(table_buf)
            result.append(f'TABLEPLACEHOLDER{counter}')
            counter += 1
        else:
            # ä¸æ˜¯æœ‰æ•ˆè¡¨æ ¼ï¼ŒåŸæ¨£ä¿ç•™
            result.extend(table_buf)
        table_buf.clear()

    for line in lines:
        if table_row_re.match(line):
            table_buf.append(line)
        else:
            if table_buf:
                flush_table()
            result.append(line)
    if table_buf:
        flush_table()

    return '\n'.join(result), tables_dict


def _parse_table_cells(row_line):
    """è§£æä¸€è¡Œè¡¨æ ¼ï¼Œå›å‚³ cell å…§å®¹æ¸…å–®ã€‚"""
    # å»æ‰é¦–å°¾çš„ |
    stripped = row_line.strip()
    if stripped.startswith('|'):
        stripped = stripped[1:]
    if stripped.endswith('|'):
        stripped = stripped[:-1]
    return [cell.strip() for cell in stripped.split('|')]


def _markdown_table_to_notion_blocks(table_lines):
    """å°‡ markdown è¡¨æ ¼è¡Œè½‰ç‚º Notion åŸç”Ÿ table blockã€‚"""
    if len(table_lines) < 2:
        return []

    header_cells = _parse_table_cells(table_lines[0])
    num_columns = len(header_cells)

    # å»ºç«‹æ‰€æœ‰ rowï¼ˆheader + data rowsï¼Œè·³é delimiter rowï¼‰
    rows = []
    for i, line in enumerate(table_lines):
        if i == 1:
            continue  # è·³éåˆ†éš”ç·š
        cells = _parse_table_cells(line)
        # ç¢ºä¿ cell æ•¸é‡èˆ‡ header ä¸€è‡´
        while len(cells) < num_columns:
            cells.append('')
        cells = cells[:num_columns]

        row = {
            "type": "table_row",
            "table_row": {
                "cells": [
                    [{"type": "text", "text": {"content": cell}}]
                    for cell in cells
                ]
            }
        }
        rows.append(row)

    table_block = {
        "object": "block",
        "type": "table",
        "table": {
            "table_width": num_columns,
            "has_column_header": True,
            "has_row_header": False,
            "children": rows
        }
    }
    return table_block


def _replace_table_placeholders(blocks, tables_dict):
    """å°‡ parse_markdown_to_notion_blocks ç”¢ç”Ÿçš„ä½”ä½ç¬¦æ®µè½æ›¿æ›ç‚º Notion table blockã€‚"""
    if not tables_dict:
        return blocks

    placeholder_re = re.compile(r'^TABLEPLACEHOLDER(\d+)$')
    result = []
    for block in blocks:
        replaced = False
        if block.get('type') == 'paragraph':
            rich_text = block.get('paragraph', {}).get('rich_text', [])
            if len(rich_text) == 1:
                text_content = rich_text[0].get('text', {}).get('content', '').strip()
                m = placeholder_re.match(text_content)
                if m:
                    idx = int(m.group(1))
                    if idx in tables_dict:
                        table_block = _markdown_table_to_notion_blocks(tables_dict[idx])
                        if table_block:
                            result.append(table_block)
                            replaced = True
        if not replaced:
            result.append(block)
    return result


_TILDE_PLACEHOLDER = '\u200BTILDE\u200B'


def _escape_single_tildes(md_text):
    """å°‡éæˆå°çš„ ~ æ›¿æ›ç‚ºä½”ä½ç¬¦ï¼Œé˜²æ­¢ md2notionpage èª¤åˆ¤ç‚º strikethroughã€‚

    md2notionpage ç”¨å–®å€‹ ~ ä½œç‚º strikethrough æ¨™è¨˜ï¼Œä½†æ¨™æº– Markdown æ˜¯ ~~ã€‚
    æ­¤å‡½å¼ä¿ç•™ ~~ï¼ˆçœŸæ­£çš„ strikethroughï¼‰ï¼Œåªè½‰ç¾©å­¤ç«‹çš„ ~ã€‚
    """
    # å…ˆä¿è­· ~~ï¼ˆæ¨™æº– strikethroughï¼‰
    md_text = md_text.replace('~~', '\x00DOUBLE_TILDE\x00')
    # è½‰ç¾©å‰©é¤˜çš„å–® ~
    md_text = md_text.replace('~', _TILDE_PLACEHOLDER)
    # é‚„åŸ ~~
    md_text = md_text.replace('\x00DOUBLE_TILDE\x00', '~~')
    return md_text


def _restore_tildes_in_blocks(blocks):
    """é‚„åŸ blocks ä¸­æ‰€æœ‰ rich_text è£¡çš„æ³¢æµªè™Ÿä½”ä½ç¬¦ã€‚"""
    for block in blocks:
        btype = block.get('type', '')
        block_data = block.get(btype, {})
        if not isinstance(block_data, dict):
            continue
        for rt in block_data.get('rich_text', []):
            text_obj = rt.get('text', {})
            if 'content' in text_obj:
                text_obj['content'] = text_obj['content'].replace(_TILDE_PLACEHOLDER, '~')
            if 'plain_text' in rt:
                rt['plain_text'] = rt['plain_text'].replace(_TILDE_PLACEHOLDER, '~')
        # éè¿´è™•ç†å­ blocks
        children = block_data.get('children', [])
        if children:
            _restore_tildes_in_blocks(children)
    return blocks


def _normalize_code_fences(md_text):
    """å°‡ code fence èªè¨€åç¨±ä¸­çš„ç©ºæ ¼æ›¿æ›ç‚ºåº•ç·šï¼Œè®“ md2notionpage çš„ \\w+ regex èƒ½æ­£ç¢ºåŒ¹é…ã€‚"""
    def _replace_lang(m):
        lang = m.group(1).strip()
        normalized = lang.replace(' ', '_')
        return f'```{normalized}\n'
    md_text = re.sub(r'```([ \w]+)\n', _replace_lang, md_text)
    # è£œä¸Š bare ``` (ç„¡èªè¨€) çš„é è¨­èªè¨€ï¼Œé¿å… md2notionpage ç„¡æ³•è§£æ
    # åªæ›¿æ› opening fenceï¼ˆé closing fenceï¼‰ï¼šç”¨ç‹€æ…‹è¿½è¹¤é…å°
    lines = md_text.split('\n')
    in_code = False
    for i, line in enumerate(lines):
        stripped = line.strip()
        if stripped.startswith('```'):
            if not in_code:
                # opening fenceï¼šå¦‚æœæ˜¯ bare ```ï¼Œè£œä¸Š text
                if stripped == '```':
                    lines[i] = line.replace('```', '```text', 1)
                in_code = True
            else:
                # closing fence
                in_code = False
    return '\n'.join(lines)


def _restore_code_languages(blocks):
    """é‚„åŸ code block èªè¨€åç¨±ä¸­çš„åº•ç·šç‚ºç©ºæ ¼ï¼ˆä¾‹å¦‚ plain_text â†’ plain textï¼‰ã€‚"""
    lang_restore_map = {
        'plain_text': 'plain text',
        'text': 'plain text',
    }
    for block in blocks:
        if block.get('type') == 'code':
            lang = block['code'].get('language', '')
            if lang in lang_restore_map:
                block['code']['language'] = lang_restore_map[lang]
        # éè¿´è™•ç†å­ blocks
        children = block.get(block.get('type', ''), {})
        if isinstance(children, dict):
            child_blocks = children.get('children', [])
            if child_blocks:
                _restore_code_languages(child_blocks)
    return blocks


def chunk_raw_content(text, chunk_size=1900):
    """å–®ç´”å°‡ç´”æ–‡å­—åˆ‡æˆç‰‡æ®µï¼Œç”¨æ–¼é‚„åŸæ©Ÿåˆ¶"""
    if not text:
        return ["(ç„¡å…§å®¹)"]
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]


def update_notion_blocks_only(page_id, ai_data, raw_content):
    """
    åƒ…æ›´æ–° Notion é é¢çš„å…§å®¹å€å¡Š (Blocks)ã€‚
    å¦‚æœå¤±æ•—ï¼Œæœƒå˜—è©¦é‚„åŸåŸå§‹å…§å®¹ç‚ºç´”æ–‡å­—ã€‚
    """
    # 1. é è™•ç†ï¼šå¤±æ•—ç›´æ¥ raiseï¼Œä¸åŸ·è¡Œ API åˆªé™¤ (é¿å…ç©ºåˆª)
    try:
        md_text = re.sub(r'<a\s+id="[^"]*">\s*</a>', '', ai_data["content"])
        md_text = _fix_malformed_tables(md_text)
        md_text = _normalize_code_fences(md_text)
        md_text = _escape_single_tildes(md_text)
        md_text, tables_dict = _extract_and_replace_tables(md_text)
        content_blocks = parse_markdown_to_notion_blocks(md_text)
        content_blocks = _replace_table_placeholders(content_blocks, tables_dict)
        content_blocks = _restore_code_languages(content_blocks)
        content_blocks = _restore_tildes_in_blocks(content_blocks)
        content_blocks = _strip_invalid_links(content_blocks)
        content_blocks = postprocess_blocks(content_blocks)
    except Exception as e:
        print(f"âŒ [é è™•ç†] å¤±æ•—: {e}")
        raise

    # 2. API æ“ä½œï¼šåŸ·è¡Œ åˆªé™¤ -> å¯«å…¥
    try:
        delete_all_blocks(page_id)
        append_blocks_batched(page_id, content_blocks)
        print(f"âœ… [Notion Blocks] å…§å®¹æ›´æ–°æˆåŠŸ: {page_id}")
    except Exception as e:
        print(f"âš ï¸ [Notion API] æ›´æ–°å¤±æ•—ï¼Œå•Ÿå‹•é‚„åŸæ©Ÿåˆ¶ã€‚éŒ¯èª¤: {e}")
        try:
            text_chunks = chunk_raw_content(raw_content)
            fallback = [
                {
                    "object": "block", 
                    "type": "paragraph",
                    "paragraph": {"rich_text": [{"type": "text", "text": {"content": chunk}}]}
                } for chunk in text_chunks
            ]
            append_blocks_batched(page_id, fallback)
            print("ğŸ”„ [Recovery] åŸå§‹å…§å®¹å·²æˆåŠŸé‚„åŸã€‚")
        except Exception as recovery_error:
            print(f"ğŸš¨ [Fatal] é€£é‚„åŸä¹Ÿå¤±æ•—äº†ï¼é é¢å¯èƒ½ç‚ºç©ºã€‚éŒ¯èª¤: {recovery_error}")
        
        # å‹™å¿…å†æ¬¡æ‹‹å‡ºéŒ¯èª¤ï¼Œè®“ main() çŸ¥æ›‰ä¸¦è·³éå¾ŒçºŒ GitHub å­˜æª”
        raise


def save_to_github(ai_result, content):
    """
    å»ºç«‹åˆ†é¡è³‡æ–™å¤¾ä¸¦å°‡ AI è™•ç†å¾Œçš„ Markdown å…§å®¹å­˜æª”è‡³æœ¬åœ°ç›®éŒ„ï¼ˆå¾ŒçºŒç”± GitHub Action Commitï¼‰ã€‚
    """
    try:
        # 1. ç¢ºä¿åˆ†é¡è³‡æ–™å¤¾å­˜åœ¨
        category_dir = f"{NOTES_DIR}/{ai_result['category']}"
        os.makedirs(category_dir, exist_ok=True)

        # 2. è™•ç†å®‰å…¨æ¨™é¡Œï¼ˆç§»é™¤æª”æ¡ˆç³»çµ±ä¸å…è¨±çš„å­—å…ƒï¼‰
        safe_title = ai_result["title"].replace("/", "-").replace("\\", "-")
        file_path = f"{category_dir}/{safe_title}.md"
        
        # 3. å–å¾—ç•¶å‰æ™‚é–“ (å°ç£æ™‚é–“)
        now = datetime.now(timezone(timedelta(hours=8))).strftime("%Y-%m-%d %H:%M")

        # 4. åœ¨ H1 æ¨™é¡Œå¾Œæ’å…¥ Updated Time è¨»è¨˜
        md_content = content
        content_lines = md_content.split('\n')
        if content_lines and content_lines[0].startswith('# '):
            # åœ¨ç¬¬ä¸€è¡Œ (# Title) ä¹‹å¾Œæ’å…¥æ›´æ–°æ™‚é–“
            content_lines.insert(1, f'\n> Updated: {now}\n')
            md_content = '\n'.join(content_lines)

        # 5. å¯«å…¥æª”æ¡ˆ
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(md_content)
            
        print(f"ğŸ’¾ [GitHub Sync] æª”æ¡ˆå·²å¯«å…¥: {file_path}")
        return file_path

    except Exception as e:
        print(f"âŒ [GitHub Sync] æª”æ¡ˆå¯«å…¥å¤±æ•—: {e}")
        raise # å‘ä¸Šæ‹‹å‡ºéŒ¯èª¤ï¼Œè®“ main() çŸ¥æ›‰ä¸¦è·³éå¾ŒçºŒçš„ Status æ›´æ–°


def main():
    pages = get_draft_pages()
    print(f"æ‰¾åˆ° {len(pages)} é å¾…è™•ç†...")
    
    # ç´€éŒ„æ˜¯å¦æœ‰ä»»ä½•ä¸€é å¤±æ•—ï¼Œç”¨ä¾†æ±ºå®šæœ€å¾Œ Workflow çš„ç‹€æ…‹
    has_any_error = False

    for page in pages:
        page_id = page["id"]
        try:
            raw_content = get_page_content(page_id)
            if not raw_content.strip():
                continue

            print(f"æ­£åœ¨è™•ç†é é¢: {page_id}ï¼Œå…§å®¹é•·åº¦: {len(raw_content)} å­—å…ƒ")

            # A. AI è™•ç†
            ai_result = organize_with_ai(raw_content)
            content = ai_result['content'].replace('\\n', '\n').replace('\\"', '"').replace('\\\\', '\\').replace('\\t', '\t')
            ai_result['content'] = content

            # B. æ›´æ–° Notion å…§å®¹ (æ­¤æ™‚ä¸æ”¹ Statusï¼Œå¤±æ•—æœƒè‡ªå‹•è§¸ç™¼ fallback)
            # æ³¨æ„ï¼šupdate_notion å…§éƒ¨ä¸æ‡‰åŒ…å«ä¿®æ”¹ Status çš„é‚è¼¯
            update_notion_blocks_only(page_id, ai_result, raw_content)

            # C. å­˜æª”è‡³ GitHub
            save_to_github(ai_result, content)

            # D. æœ€å¾Œä¸€æ­¥ï¼šæ‰€æœ‰éƒ½æˆåŠŸäº†ï¼Œæ‰ä¿®æ”¹ Notion å±¬æ€§ (Status: Done)
            # é€™æ¨£å¦‚æœä¸Šé¢ B æˆ– C å¤±æ•—ï¼Œé€™ç¯‡åœ¨ä¸‹ä¸€å°æ™‚æœƒè¢«é‡æ–°è™•ç†
            update_page_properties(page_id, ai_result)
            
            print(f"âœ… é é¢ {page_id} è™•ç†å®Œæˆã€‚")

        except Exception as e:
            print(f"âŒ è™•ç†é é¢ {page_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            has_any_error = True  # æ¨™è¨˜ç™¼ç”ŸééŒ¯èª¤
            continue # è·³éé€™ç¯‡ï¼Œè™•ç†ä¸‹ä¸€ç¯‡

        # ç¯€æµè™•ç†
        time.sleep(60)

    # å¦‚æœæœ‰ä»»ä½•ä¸€é å¤±æ•—ï¼Œå¼·åˆ¶çµæŸç¨‹å¼ä¸¦æ‹‹å‡ºéŒ¯èª¤ï¼Œè®“ GitHub Actions è®Šç´…ç‡ˆ
    if has_any_error:
        print("ğŸš¨ éƒ¨åˆ†é é¢è™•ç†å¤±æ•—ï¼Œè«‹æª¢æŸ¥ Logã€‚")
        sys.exit(1) # è®“ GitHub Action å ±éŒ¯


# def read_md_from_note(file_path):
#     """å¾æœ¬åœ° notes è³‡æ–™å¤¾è®€å– md æª”æ¡ˆå…§å®¹"""
#     with open(file_path, "r", encoding="utf-8") as f:
#         return f.read()


# if __name__ == "__main__":
#     page_id = "dbd86d185388478db501581036f3a042"
#     raw_content = "fake raw content for testing"

#     # å¾æœ¬åœ° md è®€å– content
#     md_path = os.path.join(NOTES_DIR, "10-Computer-Science", "Claude AI çŸ¥è­˜å…§åŒ–èˆ‡ LLM Context Token å„ªåŒ–ç­–ç•¥.md")
#     content = read_md_from_note(md_path)
#     ai_result = {"content": content}

#     print(f"è®€å–å…§å®¹é•·åº¦: {len(content)} å­—å…ƒ")
#     print(f"é–‹å§‹æ¸¬è©¦ update_notion_blocks_only...")
#     update_notion_blocks_only(page_id, ai_result, raw_content)
#     print("æ¸¬è©¦å®Œæˆï¼")


if __name__ == "__main__":
    print("é–‹å§‹åŸ·è¡Œ Notion ç­†è¨˜æ•´ç†èˆ‡åŒæ­¥æµç¨‹...")
    main()
